#!/usr/bin/env node

/** Debug change:
 * We would like to see stacktrace of hflow exit.
 */
process.on('exit', function() { console.trace("EXIT STACKTRACE"); });

var redisURL = process.env.REDIS_URL ? {url: process.env.REDIS_URL} : undefined

var docopt = require('docopt').docopt;

var doc = "\
Usage:\n\
  hflow run <workflow_dir_or_file> [-s] [--persist] [--with-server] [--log-provenance] [--provenance-output=<provenance_file>] [-p <plugin_module_name> ...] [--var=<name=value> ...]\n\
  hflow recover <persistence-log> [-p <plugin_module_name> ...] [--var=<name=value> ...]\n\
  hflow start-server [-p <plugin_module_name> ...]\n\
  hflow send <wf_id> ( <signal_file> | -d <signal_data> ) [-p <plugin_module_name> ...]\n\
  hflow -h | --help | --version";

var opts = docopt(doc);

if (opts['--version']) {
    console.log(require('../package.json').version);
    process.exit(0);
};

var spawn = require('child_process').spawn,
    fs = require('fs'),
    pathtool = require('path'),
    redis = require('redis'),
    rcl = redisURL ? redis.createClient(redisURL): redis.createClient(),
    wflib = require('../wflib').init(rcl),
    Engine = require('../engine2'),
    async = require('async'),
    readVars = require('../utils/readvars.js'),
    dbId = 0,
    plugins = [],
    recoveryMode = false, recoveryData = { 'input': [], 'outputs': {}, 'settings': {} },
    glob = require('glob'),
    wfDirFull; // logged in the persistence journal

var hfroot = pathtool.join(require('path').dirname(require.main.filename), "..");

// Workflow variables TODO: add support for config files
var wf_vars = readVars([], opts['--var']);

if (opts['-p']) {
    opts['<plugin_module_name>'].forEach(load_plugin);
}

if (opts.run) {
  hflow_run();
} else if (opts.send) {
  hflow_send();
} else if (opts['start-server']) {
  hflow_start();
} else if (opts.recover) {
  hflow_recover();
}

function load_plugin(plugin_name) {
    try {
        var Plugin = require(plugin_name);
        plugins.push(new Plugin());
    } catch (err) {
        console.log("Plugin module:", plugin_name, "not found!");
        console.log(err);
        process.exit(1);
    }
}

function append_file(filename, contents, cb) {
    fs.appendFile(filename, contents, function (err) {
        if (err) {
            console.log("Error appending to file! " + err);
            cb(err);
        }
        cb();
    });
}

function handle_writes(entries, cb) {
    var data = {};
    var writes = [];

    entries.forEach(function (entry) {
        var filename = entry["filename"];
        var contents = entry["args"];

        if (filename in data) {
            data[filename] += contents + '\n';
        } else {
            data[filename] = contents + '\n';
        }
    });

    for (var filename in data) {
        if (data.hasOwnProperty(filename)) {
            writes.push(function (cb) {
                    append_file(filename, data[filename], cb);
                }
            );
        }
    }

    async.parallel(writes, function (err) {
        if (err) {
            cb(err);
            return;
        }
        cb();
    });
}

var cargo = async.cargo(handle_writes, 5000);

function hflow_start() {
    var server = require('../server/hyperflow-server.js')(rcl, wflib, plugins);
    server.listen(process.env.PORT, function() { });
    console.log("HyperFlow server started, app factory URI: http://%s:%d/apps", server.address().address, server.address().port);
}

function hflow_run() {
  var wfpath = recoveryMode ? wfDirFull: opts['<workflow_dir_or_file>'], // if this is recovery, full wf dir path was already read from the journal, otherwise it will be resolved
      wfstats = fs.lstatSync(wfpath),
      wffile;

  if (opts['--with-server']) {
      hflow_start(); // start the HTTP server
  }

  if (wfstats.isDirectory()) {
    wffile = pathtool.join(wfpath, "workflow.json");
  } else if (wfstats.isFile()) {
    wffile = wfpath;
    wfpath = pathtool.dirname(wfpath);
  }

  wfDirFull = pathtool.resolve(wfpath);

  // Read workflow configuration files if exist
  // all files matching pattern `workflow.config[.name].json` will be matched
  // all config will be passed to workflow functions via `context.appConfig[.name]`
  var wfConfig = {};
  // 1. Look for main config file -- workflow.config.json
  var wfConfigFilePath = pathtool.join(wfDirFull, "workflow.config.json");
  if (fs.existsSync(wfConfigFilePath)) {
    try {
        let rawdata = fs.readFileSync(wfConfigFilePath);
        wfConfig = JSON.parse(rawdata);
    } catch(e) {
        console.log("Error reading/parsing workflow config file:", e);
    }
  }
  // 2. Look for secondary config files -- workflow.config.{name}.json
  let globOpts = {"cwd": wfDirFull, "absolute": true};
  var configFiles = glob.sync("workflow.config.*.json", globOpts);
  configFiles.forEach(function(file) {
      try {
          let rawdata = fs.readFileSync(file);
          let secondaryConfig = JSON.parse(rawdata);
          let match = file.match(/workflow\.config\.(.*).json/);
          let name = match[1];
          wfConfig[name] = secondaryConfig;
      } catch (e) {
          console.log("Error reading/parsing workflow config file ", file, e);
      }
  });

  var runWf = function(wfId, wfName) {

    /*function makeId() {
        var id = [];
        var possible = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";

        for( var i=0; i < 5; i++ )
            id[i] = possible.charAt(Math.floor(Math.random() * possible.length));

        return id.join("");
    }*/

    var config = wfConfig;
    config["emulate"] = "false";
    config["workdir"] = wfDirFull;
    
    if (recoveryMode) {
        config.recoveryData = recoveryData;
        config.recovery = true;
    }

    //console.log(JSON.stringify(recoveryData, null, 2));
    //process.exit(1);

    var engine = new Engine(config, wflib, wfId, function(err) {
      // This represent custom plugin listening on event from available eventServer
      // engine.eventServer.on('trace.*', function(exec, args) {
      //   console.log('Event captured: ' + exec + ' ' + args + ' job done');
      // });

      plugins.forEach(function(plugin) {
          plugin.init(rcl, wflib, engine);
      });

      engine.syncCb = function () {
          // TODO call wflib.closeJobConnector(wfId)
          process.exit();
      };

      if (opts['--log-provenance']) {
          engine.logProvenance = true;
          var provenance_output = opts['--provenance-output'] || 'provenance_log.txt';
          if (!pathtool.isAbsolute(provenance_output)) {
              provenance_output = pathtool.join(process.cwd(), provenance_output);
          }
          engine.eventServer.on('prov', function() {
              cargo.push( { "filename": provenance_output, "args": JSON.stringify(arguments)}, function(err) {
                  if (err) {
                      console.log("cargo errror! " + err);
                  }
              });
          });
      }


      if (opts['--persist']) { // enable persistence of workflow execution state
          // TODO: implement a plugin for different persistence backends
          // FIXME: generate unique persist-log file name
          var date = new Date().toISOString().replace(new RegExp('[T:.]', 'g'), '-').replace('Z', '');
          var logFileName = (wfName ? wfName: 'wf').concat('.' + date + ".log");
          console.log("Persistence log:", logFileName);
          var persistlog=pathtool.join(wfDirFull, logFileName);
          engine.eventServer.on('persist', function() {
              cargo.push( { "filename": persistlog, "args": JSON.stringify(arguments) }, function(err) {
                  if (err) {
                      console.log("cargo errror! " + err);
                  }
              });
          });
      }

      // we persist the full workflow directory path and execution options used to run the workflow
      engine.eventServer.emit('persist', ["info", wfDirFull, JSON.stringify(opts)]);

      engine.runInstance(function(err) {
        console.log("Wf id="+wfId);
        if (opts['-s']) {
          // Flag -s is present: send all input signals to the workflow -> start execution
          wflib.getWfIns(wfId, false, function(err, wfIns) {
            engine.wflib.getSignalInfo(wfId, wfIns, function(err, sigs) {
              engine.emitSignals(sigs);
            });
          });
        }
      });
    });
  };

  var createWf = function(cb) {
    rcl.select(dbId, function(err, rep) {
      //rcl.flushdb(function(err, rep) { // flushing db here deletes the global 'hfid' entry (created earlier)
	if (err) throw err;
        wflib.createInstanceFromFile(wffile, '', { vars: wf_vars }, function(err, id, wfJson) {
          cb(err, id, wfJson.name);
        });
      //});
    });
  }

   var startWf = function() {
       createWf(function (err, wfId, wfName) {
           runWf(wfId, wfName);
       });
   };

   startWf();
}

function hflow_recover() {
    var recoveryFile = opts['<persistence-log>'];
    var persistLog = fs.readFileSync(recoveryFile, 'utf8').toString().trim().split('\n');
    persistLog.forEach((entry, index) => persistLog[index] = JSON.parse(entry));

    persistLog.forEach(function(plogentry) {
        let entry = plogentry['1'];
        let settings = plogentry['2'];
        if (entry[0] == 'info') { // full wf dir path and command line options
            wfDirFull = entry[1]; 
            opts = JSON.parse(entry[2]); // we recover command line options used to run the workflow
            opts.s = false; // option 's' shold never be true when recovering (to be removed altogether)
        } else if (entry[0] == 'input') {
            var sigData = entry[2];
            delete sigData.sigIdx;
            recoveryData['input'].push(sigData);
        } else if (entry[0] == 'fired') {
            var procId = entry[2], 
            firingId = entry[3], 
            outs = entry[4],
            key = procId + '_' + firingId;
            recoveryData.outputs[key] = outs;
            if (settings) { // additional annotations, flags, e.g. 'forceRecompute'
                recoveryData.settings[key] = settings;
            }
        }
    });

    recoveryMode = true;

    hflow_run();
}

function hflow_send() {
  console.log("send signal to a workflow: not implemented");
}

function spawn_proc(exec, args) {
  var proc = spawn(exec, args);

  proc.stdout.on('data', function(data) {
    console.log(data.toString().trimRight());
  });

  proc.stderr.on('data', function(data) {
    console.log(data.toString().trimRight());
  });
}
